Metadata-Version: 2.1
Name: divergence
Version: 0.1.0
Summary: Compute Statistical Measures of Divergence
Home-page: https://github.com/michaelnowotny/divergence
Author: Michael Christoph Nowotny
Author-email: nowotnym@gmail.com
License: MIT
Platform: UNKNOWN
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.6
Classifier: Programming Language :: Python :: 3.7
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: Implementation :: CPython
Requires-Python: >=3.6.0
Description-Content-Type: text/markdown
Requires-Dist: numpy
Requires-Dist: pytest
Requires-Dist: scipy
Requires-Dist: statsmodels


# Divergence
Divergence is a Python package to compute statistical measures of entropy and divergence from probability distributions and samples.

The following functionality is provided:
* (Information) Entropy
* Relative Entropy or Kullback-Leibler Divergence
* Jensen-Shannon Divergence

## Installation

<pre>
    pip install divergence
</pre>

## Examples
See the Jupyter notebook [Divergence](notebooks/Divergence.ipynb).

