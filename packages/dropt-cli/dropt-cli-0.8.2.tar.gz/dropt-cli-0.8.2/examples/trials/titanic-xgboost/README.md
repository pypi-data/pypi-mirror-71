# Prediction on Titanic survivors with XGBoost
This example demonstrates the XGBoost classification model.
It is based on the [Titanic survival prediction competition on Kaggle][ref:titanic].


## Run model script
Enter the following command to train/evaluate the model with default
hyper-parameter configuration:
```console
$ python xgb.py
```

To know about more options, enter
```console
$ python xgb.py -h
```


## Apply DrOpt service
See trial readme.



[ref:titanic]: https://www.kaggle.com/c/titanic
[ref:xgboost]: https://xgboost.readthedocs.io/en/latest/parameter.html
