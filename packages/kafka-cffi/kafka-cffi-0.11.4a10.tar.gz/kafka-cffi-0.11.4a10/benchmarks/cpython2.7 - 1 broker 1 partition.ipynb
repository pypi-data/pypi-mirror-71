{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('CPython', '2.7.12')\n"
     ]
    }
   ],
   "source": [
    "from kafka_cffi import Producer as cffi_Producer\n",
    "from confluent_kafka import Producer as confluent_Producer\n",
    "import time\n",
    "import platform\n",
    "\n",
    "conf = {\n",
    "    \"bootstrap.servers\": \"n1.kafka10.service.consul:9092\",\n",
    "    \"queue.buffering.max.messages\": \"1000000\",\n",
    "    \"queue.buffering.max.kbytes\": \"2097151\",\n",
    "    \"acks\": \"1\",\n",
    "#     \"compression.codec\": \"snappy\",\n",
    "}\n",
    "\n",
    "cffi_prod = cffi_Producer(conf)\n",
    "confluent_prod = confluent_Producer(conf)\n",
    "\n",
    "def callback(err, msg):\n",
    "    pass\n",
    "\n",
    "def benchmark(prod, samples, per_batch, msg_length=100, on_delivery=None):\n",
    "    print(type(prod))\n",
    "    timings = []\n",
    "    for s in range(samples):\n",
    "        t = time.time()\n",
    "        for i in range(per_batch):\n",
    "            prod.produce(\"moo\", \"0\" * msg_length, on_delivery=on_delivery)\n",
    "        prod.flush(-1)\n",
    "        timings.append(time.time() - t)\n",
    "    \n",
    "    print(\"%d Samples, %d msgs per batch, %d bytes/msg\" % (samples, per_batch, msg_length))\n",
    "    print(\"Mean (per batch): %0.3f msgs/sec\" % (sum(per_batch / x for x in timings) / samples))\n",
    "    print(\"Mean (overall): %0.3f msgs/sec\" % (samples * per_batch / sum(timings)))\n",
    "    print(\"Fastest batch: %0.3f msgs/sec\" % (per_batch / min(timings)))\n",
    "    print(\"Slowest batch: %0.3f msgs/sec\" % (per_batch / max(timings)))\n",
    "    \n",
    "print(platform.python_implementation(), platform.python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0L"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    # warm cold topic up first for both clients to be fair\n",
    "    cffi_prod.produce(\"moo\", \"hello world\")\n",
    "    confluent_prod.produce(\"moo\", \"hello world\")\n",
    "    \n",
    "cffi_prod.flush()\n",
    "confluent_prod.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'kafka_cffi.producer.Producer'>\n",
      "30 Samples, 100000 msgs per batch, 100 bytes/msg\n",
      "Mean (per batch): 298781.690 msgs/sec\n",
      "Mean (overall): 284922.807 msgs/sec\n",
      "Fastest batch: 402741.981 msgs/sec\n",
      "Slowest batch: 178959.719 msgs/sec\n",
      "<type 'cimpl.Producer'>\n",
      "30 Samples, 100000 msgs per batch, 100 bytes/msg\n",
      "Mean (per batch): 383659.838 msgs/sec\n",
      "Mean (overall): 358810.563 msgs/sec\n",
      "Fastest batch: 540417.434 msgs/sec\n",
      "Slowest batch: 211921.836 msgs/sec\n"
     ]
    }
   ],
   "source": [
    "benchmark(cffi_prod, samples=30, per_batch=100000, msg_length=100)\n",
    "benchmark(confluent_prod, samples=30, per_batch=100000, msg_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'kafka_cffi.producer.Producer'>\n",
      "60 Samples, 20000 msgs per batch, 450 bytes/msg\n",
      "Mean (per batch): 165611.219 msgs/sec\n",
      "Mean (overall): 152869.169 msgs/sec\n",
      "Fastest batch: 308655.488 msgs/sec\n",
      "Slowest batch: 72749.764 msgs/sec\n",
      "<type 'cimpl.Producer'>\n",
      "60 Samples, 20000 msgs per batch, 450 bytes/msg\n",
      "Mean (per batch): 228022.150 msgs/sec\n",
      "Mean (overall): 215962.537 msgs/sec\n",
      "Fastest batch: 414293.165 msgs/sec\n",
      "Slowest batch: 122876.520 msgs/sec\n"
     ]
    }
   ],
   "source": [
    "benchmark(cffi_prod, samples=60, per_batch=20000, msg_length=450)\n",
    "benchmark(confluent_prod, samples=60, per_batch=20000, msg_length=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'kafka_cffi.producer.Producer'>\n",
      "60 Samples, 20000 msgs per batch, 450 bytes/msg\n",
      "Mean (per batch): 115232.191 msgs/sec\n",
      "Mean (overall): 109551.825 msgs/sec\n",
      "Fastest batch: 171825.876 msgs/sec\n",
      "Slowest batch: 65738.402 msgs/sec\n",
      "<type 'cimpl.Producer'>\n",
      "60 Samples, 20000 msgs per batch, 450 bytes/msg\n",
      "Mean (per batch): 226061.302 msgs/sec\n",
      "Mean (overall): 216108.982 msgs/sec\n",
      "Fastest batch: 454329.739 msgs/sec\n",
      "Slowest batch: 123298.420 msgs/sec\n"
     ]
    }
   ],
   "source": [
    "# performance with a noop callback\n",
    "benchmark(cffi_prod, samples=60, per_batch=20000, msg_length=450, on_delivery=callback)\n",
    "benchmark(confluent_prod, samples=60, per_batch=20000, msg_length=450, on_delivery=callback)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
