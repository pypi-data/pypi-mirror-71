{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('PyPy', '2.7.13')\n"
     ]
    }
   ],
   "source": [
    "from kafka_cffi import Producer as cffi_Producer\n",
    "from confluent_kafka import Producer as confluent_Producer\n",
    "import time\n",
    "import platform\n",
    "\n",
    "conf = {\n",
    "    \"bootstrap.servers\": \"n1.kafka10.service.consul:9092\",\n",
    "    \"queue.buffering.max.messages\": \"1000000\",\n",
    "    \"queue.buffering.max.kbytes\": \"2097151\",\n",
    "    \"acks\": \"1\",\n",
    "#     \"compression.codec\": \"snappy\",\n",
    "}\n",
    "\n",
    "cffi_prod = cffi_Producer(conf)\n",
    "confluent_prod = confluent_Producer(conf)\n",
    "\n",
    "def callback(err, msg):\n",
    "    pass\n",
    "\n",
    "def benchmark(prod, samples, per_batch, msg_length=100, on_delivery=None):\n",
    "    print(type(prod))\n",
    "    timings = []\n",
    "    for s in range(samples):\n",
    "        t = time.time()\n",
    "        for i in range(per_batch):\n",
    "            prod.produce(\"moo\", \"0\" * msg_length, on_delivery=on_delivery)\n",
    "        prod.flush(-1)\n",
    "        timings.append(time.time() - t)\n",
    "    \n",
    "    print(\"%d Samples, %d msgs per batch, %d bytes/msg\" % (samples, per_batch, msg_length))\n",
    "    print(\"Mean (per batch): %0.3f msgs/sec\" % (sum(per_batch / x for x in timings) / samples))\n",
    "    print(\"Mean (overall): %0.3f msgs/sec\" % (samples * per_batch / sum(timings)))\n",
    "    print(\"Fastest batch: %0.3f msgs/sec\" % (per_batch / min(timings)))\n",
    "    print(\"Slowest batch: %0.3f msgs/sec\" % (per_batch / max(timings)))\n",
    "    \n",
    "print(platform.python_implementation(), platform.python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0L"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    # warm cold topic up first for both clients to be fair\n",
    "    cffi_prod.produce(\"moo\", \"hello world\")\n",
    "    confluent_prod.produce(\"moo\", \"hello world\")\n",
    "    \n",
    "cffi_prod.flush()\n",
    "confluent_prod.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'kafka_cffi.producer.Producer'>\n",
      "30 Samples, 100000 msgs per batch, 100 bytes/msg\n",
      "Mean (per batch): 902266.140 msgs/sec\n",
      "Mean (overall): 806266.819 msgs/sec\n",
      "Fastest batch: 1190985.061 msgs/sec\n",
      "Slowest batch: 231103.226 msgs/sec\n",
      "<type 'cimpl.Producer'>\n",
      "30 Samples, 100000 msgs per batch, 100 bytes/msg\n",
      "Mean (per batch): 212746.361 msgs/sec\n",
      "Mean (overall): 205116.147 msgs/sec\n",
      "Fastest batch: 299744.942 msgs/sec\n",
      "Slowest batch: 119480.591 msgs/sec\n"
     ]
    }
   ],
   "source": [
    "benchmark(cffi_prod, samples=30, per_batch=100000, msg_length=100)\n",
    "benchmark(confluent_prod, samples=30, per_batch=100000, msg_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'kafka_cffi.producer.Producer'>\n",
      "60 Samples, 20000 msgs per batch, 450 bytes/msg\n",
      "Mean (per batch): 421290.130 msgs/sec\n",
      "Mean (overall): 392536.391 msgs/sec\n",
      "Fastest batch: 591642.840 msgs/sec\n",
      "Slowest batch: 148628.247 msgs/sec\n",
      "<type 'cimpl.Producer'>\n",
      "60 Samples, 20000 msgs per batch, 450 bytes/msg\n",
      "Mean (per batch): 114376.228 msgs/sec\n",
      "Mean (overall): 105116.919 msgs/sec\n",
      "Fastest batch: 220068.314 msgs/sec\n",
      "Slowest batch: 55570.219 msgs/sec\n"
     ]
    }
   ],
   "source": [
    "benchmark(cffi_prod, samples=60, per_batch=20000, msg_length=450)\n",
    "benchmark(confluent_prod, samples=60, per_batch=20000, msg_length=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'kafka_cffi.producer.Producer'>\n",
      "60 Samples, 20000 msgs per batch, 450 bytes/msg\n",
      "Mean (per batch): 317071.627 msgs/sec\n",
      "Mean (overall): 277635.114 msgs/sec\n",
      "Fastest batch: 478228.607 msgs/sec\n",
      "Slowest batch: 62312.450 msgs/sec\n",
      "<type 'cimpl.Producer'>\n",
      "60 Samples, 20000 msgs per batch, 450 bytes/msg\n",
      "Mean (per batch): 66119.658 msgs/sec\n",
      "Mean (overall): 64036.089 msgs/sec\n",
      "Fastest batch: 95028.128 msgs/sec\n",
      "Slowest batch: 40538.679 msgs/sec\n"
     ]
    }
   ],
   "source": [
    "# performance with a noop callback\n",
    "benchmark(cffi_prod, samples=60, per_batch=20000, msg_length=450, on_delivery=callback)\n",
    "benchmark(confluent_prod, samples=60, per_batch=20000, msg_length=450, on_delivery=callback)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
