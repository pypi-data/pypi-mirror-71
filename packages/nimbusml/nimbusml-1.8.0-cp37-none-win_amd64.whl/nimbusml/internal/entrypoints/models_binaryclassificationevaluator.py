# - Generated by tools/entrypoint_compiler.py: do not edit by hand
"""
Models.BinaryClassificationEvaluator
"""

import numbers

from ..utils.entrypoints import EntryPoint
from ..utils.utils import try_set, unlist


def models_binaryclassificationevaluator(
        data,
        warnings=None,
        overall_metrics=None,
        per_instance_metrics=None,
        confusion_matrix=None,
        name_column='Name',
        probability_column=None,
        threshold=0.0,
        use_raw_score_threshold=True,
        num_roc_examples=100000,
        max_auc_examples=-1,
        num_au_prc_examples=100000,
        label_column=None,
        weight_column=None,
        score_column=None,
        strat_column=None,
        **params):
    """
    **Description**
        Evaluates a binary classification scored dataset.

    :param data: The data to be used for evaluation. (inputs).
    :param name_column: Name column name. (inputs).
    :param probability_column: Probability column name (inputs).
    :param threshold: Probability value for classification
        thresholding (inputs).
    :param use_raw_score_threshold: Use raw score value instead of
        probability for classification thresholding (inputs).
    :param num_roc_examples: The number of samples to use for p/r
        curve generation. Specify 0 for no p/r curve generation
        (inputs).
    :param max_auc_examples: The number of samples to use for AUC
        calculation. If 0, AUC is not computed. If -1, the whole
        dataset is used (inputs).
    :param num_au_prc_examples: The number of samples to use for
        AUPRC calculation. Specify 0 for no AUPRC calculation
        (inputs).
    :param label_column: Column to use for labels. (inputs).
    :param weight_column: Weight column name. (inputs).
    :param score_column: Score column name. (inputs).
    :param strat_column: Stratification column name. (inputs).
    :param warnings: Warning dataset (outputs).
    :param overall_metrics: Overall metrics dataset (outputs).
    :param per_instance_metrics: Per instance metrics dataset
        (outputs).
    :param confusion_matrix: Confusion matrix dataset (outputs).
    """

    entrypoint_name = 'Models.BinaryClassificationEvaluator'
    inputs = {}
    outputs = {}

    if data is not None:
        inputs['Data'] = try_set(
            obj=data,
            none_acceptable=False,
            is_of_type=str)
    if name_column is not None:
        inputs['NameColumn'] = try_set(
            obj=name_column,
            none_acceptable=True,
            is_of_type=str,
            is_column=True)
    if probability_column is not None:
        inputs['ProbabilityColumn'] = try_set(
            obj=probability_column,
            none_acceptable=True,
            is_of_type=str,
            is_column=True)
    if threshold is not None:
        inputs['Threshold'] = try_set(
            obj=threshold,
            none_acceptable=True,
            is_of_type=numbers.Real)
    if use_raw_score_threshold is not None:
        inputs['UseRawScoreThreshold'] = try_set(
            obj=use_raw_score_threshold,
            none_acceptable=True,
            is_of_type=bool)
    if num_roc_examples is not None:
        inputs['NumRocExamples'] = try_set(
            obj=num_roc_examples,
            none_acceptable=True,
            is_of_type=numbers.Real)
    if max_auc_examples is not None:
        inputs['MaxAucExamples'] = try_set(
            obj=max_auc_examples,
            none_acceptable=True,
            is_of_type=numbers.Real)
    if num_au_prc_examples is not None:
        inputs['NumAuPrcExamples'] = try_set(
            obj=num_au_prc_examples,
            none_acceptable=True,
            is_of_type=numbers.Real)
    if label_column is not None:
        inputs['LabelColumn'] = try_set(
            obj=label_column,
            none_acceptable=True,
            is_of_type=str,
            is_column=True)
    if weight_column is not None:
        inputs['WeightColumn'] = try_set(
            obj=weight_column,
            none_acceptable=True,
            is_of_type=str,
            is_column=True)
    if score_column is not None:
        inputs['ScoreColumn'] = try_set(
            obj=score_column,
            none_acceptable=True,
            is_of_type=str,
            is_column=True)
    if strat_column is not None:
        inputs['StratColumn'] = try_set(
            obj=strat_column,
            none_acceptable=True,
            is_of_type=list,
            is_column=True)
    if warnings is not None:
        outputs['Warnings'] = try_set(
            obj=warnings, none_acceptable=False, is_of_type=str)
    if overall_metrics is not None:
        outputs['OverallMetrics'] = try_set(
            obj=overall_metrics, none_acceptable=False, is_of_type=str)
    if per_instance_metrics is not None:
        outputs['PerInstanceMetrics'] = try_set(
            obj=per_instance_metrics, none_acceptable=False, is_of_type=str)
    if confusion_matrix is not None:
        outputs['ConfusionMatrix'] = try_set(
            obj=confusion_matrix, none_acceptable=False, is_of_type=str)

    input_variables = {
        x for x in unlist(inputs.values())
        if isinstance(x, str) and x.startswith("$")}
    output_variables = {
        x for x in unlist(outputs.values())
        if isinstance(x, str) and x.startswith("$")}

    entrypoint = EntryPoint(
        name=entrypoint_name, inputs=inputs, outputs=outputs,
        input_variables=input_variables,
        output_variables=output_variables)
    return entrypoint
